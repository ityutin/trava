{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Trava for parameters & metrics autotracking with MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: MLFlow is only one of possible implementations of trava.tracker.Tracker interface. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "dataset = datasets.load_breast_cancer()\n",
    "df = pd.DataFrame(dataset['data'], columns=dataset['feature_names'])\n",
    "df['target'] = dataset['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure which metrics to track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we list metrics we want `MLFlow` to track. \n",
    "\n",
    "`sk` is a wrapper around `scikit-learn's` `make_scorer` function. \n",
    "\n",
    "`sk_proba` is the same, but for metrics that require probabilities instead of labels.\n",
    "\n",
    "You can put any metric in the list, but it must be wrapped in `trava.scorer.Scorer`, see the class implementation for the details.\n",
    "\n",
    "`FitTimeScorer` and `PredictTimeScorer` are examples of custom metrics that have nothing to do with prediction-related metrics. We can track anything that we find useful for our case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 'mlflow_demo' does not exist. Creating a new experiment\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss, roc_auc_score, recall_score, precision_score\n",
    "from trava.ext.sklearn.scorers import sk, sk_proba\n",
    "from trava.ext.tracker.mlflow import MLFlowTracker\n",
    "from trava.ext.scorers.model_scorers import FitTimeScorer, PredictTimeScorer\n",
    "\n",
    "tracker_scorers = [\n",
    "    sk_proba(log_loss),\n",
    "    sk_proba(roc_auc_score),\n",
    "    sk(recall_score),\n",
    "    sk(precision_score),\n",
    "    FitTimeScorer(),\n",
    "    PredictTimeScorer()\n",
    "]\n",
    "\n",
    "tracker = MLFlowTracker(scorers=tracker_scorers)\n",
    "# setting the new experiment\n",
    "tracker.track_set_tracking_group(group='mlflow_demo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just `Trava's` way of making train/test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trava.ext.split_logic.basic import BasicSplitLogic\n",
    "from trava.split.config import DataSplitConfig\n",
    "from trava.split.result import SplitResult\n",
    "from trava.split.splitter import Splitter\n",
    "\n",
    "# Trava comes with some built-in options for splitting data,\n",
    "# yet you can subclass trava.split.SplitLogic for something that suits you\n",
    "split_config = DataSplitConfig(split_logic=BasicSplitLogic(shuffle=True),\n",
    "                               target_col_name='target',\n",
    "                               test_size=0.3)\n",
    "\n",
    "split_result = Splitter.split(df=df, config=split_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Trava"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `TravaSV` instance to train and assess our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trava.trava_sv import TravaSV\n",
    "\n",
    "trava = TravaSV(tracker=tracker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Both default and user-provided parameters of the model will be tracked automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ilya.tyutin/anaconda3/lib/python3.7/site-packages/py4j/java_collections.py:13: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import (\n",
      "/Users/ilya.tyutin/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# the following is roughly the same as:\n",
    "# log_reg = LogisticRegression(C=1)\n",
    "# log_reg.fit(split_result.X_train, split_result.y_train)\n",
    "# log_reg.predict(split_result.X_test)\n",
    "trava.fit_predict(raw_split_data=split_result,\n",
    "                  model_id='log_reg',\n",
    "                  model_type=LogisticRegression,\n",
    "                  model_init_params={'C': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actually, that's all you need to do!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making sure that everything is tracked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>status</th>\n",
       "      <th>artifact_uri</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>metrics.recall_score</th>\n",
       "      <th>metrics.predict_time</th>\n",
       "      <th>metrics.fit_time</th>\n",
       "      <th>metrics.precision_score</th>\n",
       "      <th>...</th>\n",
       "      <th>params.verbose</th>\n",
       "      <th>params.fit_intercept</th>\n",
       "      <th>params.penalty</th>\n",
       "      <th>params.dual</th>\n",
       "      <th>params.intercept_scaling</th>\n",
       "      <th>tags.mlflow.user</th>\n",
       "      <th>tags.mlflow.runName</th>\n",
       "      <th>tags.mlflow.source.name</th>\n",
       "      <th>tags.mlflow.source.type</th>\n",
       "      <th>tags.model_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2551943ef876419c9bedbc4f79a27d1d</td>\n",
       "      <td>1</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>file:///Users/ilya.tyutin/Projects/trava/examp...</td>\n",
       "      <td>2020-05-24 13:59:52.052000+00:00</td>\n",
       "      <td>2020-05-24 13:59:52.123000+00:00</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.019371</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>ilya.tyutin</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>/Users/ilya.tyutin/anaconda3/lib/python3.7/sit...</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             run_id experiment_id    status  \\\n",
       "0  2551943ef876419c9bedbc4f79a27d1d             1  FINISHED   \n",
       "\n",
       "                                        artifact_uri  \\\n",
       "0  file:///Users/ilya.tyutin/Projects/trava/examp...   \n",
       "\n",
       "                        start_time                         end_time  \\\n",
       "0 2020-05-24 13:59:52.052000+00:00 2020-05-24 13:59:52.123000+00:00   \n",
       "\n",
       "   metrics.recall_score  metrics.predict_time  metrics.fit_time  \\\n",
       "0              0.916667              0.001057          0.019371   \n",
       "\n",
       "   metrics.precision_score  ...  params.verbose  params.fit_intercept  \\\n",
       "0                 0.942857  ...               0                  True   \n",
       "\n",
       "  params.penalty params.dual params.intercept_scaling tags.mlflow.user  \\\n",
       "0             l2       False                        1      ilya.tyutin   \n",
       "\n",
       "  tags.mlflow.runName                            tags.mlflow.source.name  \\\n",
       "0             log_reg  /Users/ilya.tyutin/anaconda3/lib/python3.7/sit...   \n",
       "\n",
       "  tags.mlflow.source.type     tags.model_type  \n",
       "0                   LOCAL  LogisticRegression  \n",
       "\n",
       "[1 rows x 28 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_id = mlflow.get_experiment_by_name('mlflow_demo').experiment_id\n",
    "runs = mlflow.search_runs(experiment_ids=[experiment_id])\n",
    "runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining the run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As you see, all the metrics as well as parameters are tracked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Run: data=<RunData: metrics={'fit_time': 0.01937103271484375,\n",
       " 'log_loss': 0.17052001191715066,\n",
       " 'precision_score': 0.9428571428571428,\n",
       " 'predict_time': 0.0010571479797363281,\n",
       " 'recall_score': 0.9166666666666666,\n",
       " 'roc_auc_score': 0.983392122281011}, params={'C': '1',\n",
       " 'dual': 'False',\n",
       " 'fit_intercept': 'True',\n",
       " 'intercept_scaling': '1',\n",
       " 'max_iter': '100',\n",
       " 'multi_class': 'auto',\n",
       " 'penalty': 'l2',\n",
       " 'solver': 'lbfgs',\n",
       " 'tol': '0.0001',\n",
       " 'verbose': '0',\n",
       " 'warm_start': 'False'}, tags={'mlflow.runName': 'log_reg',\n",
       " 'mlflow.source.name': '/Users/ilya.tyutin/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py',\n",
       " 'mlflow.source.type': 'LOCAL',\n",
       " 'mlflow.user': 'ilya.tyutin',\n",
       " 'model_type': 'LogisticRegression'}>, info=<RunInfo: artifact_uri='file:///Users/ilya.tyutin/Projects/trava/examples/mlruns/1/2551943ef876419c9bedbc4f79a27d1d/artifacts', end_time=1590328792123, experiment_id='1', lifecycle_stage='active', run_id='2551943ef876419c9bedbc4f79a27d1d', run_uuid='2551943ef876419c9bedbc4f79a27d1d', start_time=1590328792052, status='FINISHED', user_id='ilya.tyutin'>>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.get_run(runs.iloc[0]['run_id'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
